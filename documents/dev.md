


keywords
研究的对象。
也是交互的基础。

keyword_data_logs （GTRENDS包）关键词数据日志，所有日志都在里面。每次写开关判断是否重复存，每次读开关判断读最新还是最旧。
id
keyword 关键词，原样


需求
现有path和filename若干。按path分类。filename经过字符处理，成为作为研究对象的keyword。也就是google里面的search term。
获取keyword在谷歌趋势对应的最接近的topic。定义，topic_title字符最接近。可通过自动补全，相关topic获取。
从谷歌趋势获取topic对应的geo等数据，进行分析。最好可以直观使用sql分析，即topic和geo自动关联。

获取某个 geo 在第一位对应的 keyword。或者其他需求，总之都是。
获取 keyword，根据geo数量排名。或者根据geo value之和。


缓存请求响应
explore类，无参数类，和其他类。
explore可以通过方法，keyword或keyword数组，参数option，额外参数，当前。确定唯一值。比较长的参数例如option可以采用json之后md5。
无参数类可以直接通过方法查找，额外日期都不需要。
其他类，比如趋势等，最新的不需要缓存。历史的，可以把参数拼接视为一个option。通过payload识别也可以。
其实用uri最好，但是监听不到，并且不能排除有隐藏参数，最好全用显式参数。
可以保存返回json历史记录，节省请求。
如果想要忽略日期更新，比如默认不输入日期time为空，还可以忽略日期。
缓存以这个包为准，因为不同包的名字字段可能不同，解析也不同。
表设计，最好不同表和模型。即同一个表里面数据结构也相似，是同一类数据，方便管理。


分析
data结果对应什么？只要有keyword，就对应keyword。不管是topic，query，还是其他不存在结果的输入。没有keyword的，属于另一种data。
explore结果对应什么？必然是keyword。explore全部都有keyword。
keyword和topic的关系是什么？其实是一对一。google会自动把term映射为对应mid的topic，如果存在。
geo要不要单独


json数据
data，如果更新后不为空，而且md5不一样，则采用最新。
log，

数据量估计
keywords对应的explore，天天分分秒秒可能都变。
趋势，也可能都变。
时间需求，有效期判断，天。
绝对值。

分析，根据现有json，其实生成各种关联分析很快，随时可以重构。也就是说，只要基础数据确定了以什么版本为准进行分析，关联数据随时可以更新看最新。



数据结构
word，词，人工产生数据，word作为研究对象。可以多对多分类。人的语言。英文中文等各种语言。各种方式导入到数据库。只随着研究不同而变化。人工理解也是根据word进行的。
word set集合，对word进行的分类，可以多对多关联。
term，谷歌趋势里面搜索的对象，可能是topic或者query或者普通term。所用的包里面叫keyword，但最好不要耦合避免和word歧义。搜索结果，topic全面，query精准，term备选。结果也是针对term的。
topic，一般稳定，mid和title等都稳定。存起来有一定意义，作为term的一对一关联，如果不空。每个topic都是term，但每个term不一定有topic。
query，一般稳定。但是其实存起来没什么关系计算需要。一般在结果json里面需要的时候查看。
geo，中长期应该也会稳定不变，如果变了，那么老数据也可以更新了，一般没必要单独保存老数据。但也不排除想要保存日志。可以通过统一日志捞数据。
cache，缓存，key，value。一般永久，偶尔过期。key偶尔加日期。

log日志/历史/bak。人工的没有这个顾虑，因为人工没有这个维护能力，只能每次用最新版。机器才有这个可能。如果需要保存历史，可以模仿git，平时使用唯一最新版本。要使用历史版本，必须回退，不能直接使用历史版本进行操作。注意，日志版本是指请求的时间，不是指谷歌趋势的历史数据，例如当前检索2008的数据。所以为了避免歧义，尽量不用历史，而用log或者bak。这个需求并不频繁。手动对老表重命名备份，然后重建空表也可以。建议，人工的在前或者在后加bak_归档或记录对应的日期时间，自动的用log。
------
log日志。可以用cache代替。key加日期即可。
bak备份。人工需要时再创建，复制一个。
